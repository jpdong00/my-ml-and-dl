{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/bayes1.png\" width=600 height=400 align='left'/>  \n",
    "<img src=\"../img/bayes2.png\" width=500 height=400 align='left'/>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB:\n",
    "    def __init__(self, lambda_):\n",
    "        self.lambda_ = lambda_  # 拉普拉斯平滑\n",
    "        self.feat_val = [0, 1]  # 文本分类中每一列特征的取值\n",
    "        self.py = {}\n",
    "        self.pxy = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        N, M = X.shape\n",
    "        data = np.hstack((X, y.reshape(N, 1)))\n",
    "\n",
    "        # 统计标签中的类别及其个数，即\\sum{I(y_i=c_k)}\n",
    "        unique_y, counts_y = np.unique(y, return_counts=True)\n",
    "        y_info = dict(zip(unique_y, counts_y))\n",
    "\n",
    "        # 对每一个类别进行遍历\n",
    "        for ck, ck_count in y_info.items():\n",
    "            # 计算P(Y=c_k)\n",
    "            self.py['P(Y={})'.format(ck)] = (ck_count + self.lambda_) / (N + len(unique_y) * self.lambda_)\n",
    "\n",
    "            # 取出标签=ck的所有行\n",
    "            tmp_data = data[data[:, -1] == ck]\n",
    "\n",
    "            # 对每一个特征遍历\n",
    "            for col in range(M):\n",
    "                # 统计类别为ck且该列特征下每个取值的个数，即\\sum{I(x_ij=a_jl,y_i=c_k)}\n",
    "                unique_feat, counts_feat = np.unique(tmp_data[:, col], return_counts=True)\n",
    "                feat_info = dict(zip(unique_feat, counts_feat))\n",
    "                # 如果该类别下的特征的取值全相等，那也需要把其它取值也加入到feat_info中\n",
    "                if len(feat_info) != len(self.feat_val):\n",
    "                    for v in self.feat_val:\n",
    "                        feat_info[v] = feat_info.get(v, 0)\n",
    "                # 对该特征下的每一个不同取值进行遍历\n",
    "                for feat_val, feat_count in feat_info.items():\n",
    "                    # 计算P(X^{j}=a_{j_l}|Y=c_k)\n",
    "                    self.pxy['P(X({})={}|Y={})'.format(col + 1, feat_val, ck)] = (feat_count + self.lambda_) / (\n",
    "                        (ck_count + len(feat_info) * self.lambda_))\n",
    "\n",
    "    def predict(self, x):\n",
    "        res = {}\n",
    "        for k, v in self.py.items():\n",
    "            p = np.log(v)\n",
    "            ck = k.split('=')[-1][:-1]\n",
    "            for i in range(len(x)):\n",
    "                # 计算P(Y=c_k)\\prod{P(X^{(j)}=x^{(j)}|Y=c_{k})}\n",
    "                p = p + np.log(self.pxy['P(X({})={}|Y={})'.format(i + 1, x[i], ck)])\n",
    "            res[ck] = p\n",
    "        # print(res)\n",
    "\n",
    "        max_p = float('-inf')\n",
    "        max_cate = float('-inf')\n",
    "        for cate, p in res.items():\n",
    "            if p > max_p:\n",
    "                max_p = p\n",
    "                max_cate = cate\n",
    "\n",
    "        return max_cate, max_p\n",
    "    \n",
    "    def score(self, Xtest, ytest):\n",
    "        c = 0\n",
    "        for x, y in zip(Xtest, ytest):\n",
    "            cate, p = self.predict(x)\n",
    "            if int(cate) == int(y):\n",
    "                c += 1\n",
    "        return c / len(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最可能的类别: -1\n"
     ]
    }
   ],
   "source": [
    "# 统计学习方法例4.1\n",
    "d = {'S': 0, 'M': 1, 'L': 2}\n",
    "X = np.array([[1, d['S']], [1, d['M']], [1, d['M']],\n",
    "              [1, d['S']], [1, d['S']], [2, d['S']],\n",
    "              [2, d['M']], [2, d['M']], [2, d['L']],\n",
    "              [2, d['L']], [3, d['L']], [3, d['M']],\n",
    "              [3, d['M']], [3, d['L']], [3, d['L']]])\n",
    "y = np.array([-1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1])\n",
    "\n",
    "model = NB(lambda_=0.2)\n",
    "model.fit(X, y)\n",
    "cate, p = model.predict(np.array([2, 0]))\n",
    "print(\"最可能的类别: {}\".format(cate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例：垃圾邮件检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清洗：转为小写，去掉少于2个字符的字符串\n",
    "def text_parse(big_str):\n",
    "    token_list = re.split(r'\\W+', big_str)  # \\W：匹配任何非单词字符\n",
    "    if len(token_list) == 0:\n",
    "        print(token_list)\n",
    "    return [tok.lower() for tok in token_list if len(tok) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入数据\n",
    "doc_list = []\n",
    "class_list = []\n",
    "for filename in ['ham', 'spam']:\n",
    "    for i in range(1, 26):\n",
    "        with open(\"./email/\" + filename + '/' + str(i) + '.txt') as f:\n",
    "            words = f.read()\n",
    "            words = text_parse(words)\n",
    "        doc_list.append(' '.join(words))\n",
    "        if filename == 'ham':\n",
    "            class_list.append(1)\n",
    "        else:\n",
    "            class_list.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单词计数\n",
    "vec = CountVectorizer()\n",
    "words = vec.fit_transform(doc_list)\n",
    "words = pd.DataFrame(words.toarray(), columns=vec.get_feature_names())\n",
    "# 转为二值，单词出现为0，没出现为1\n",
    "words[words > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0nline</th>\n",
       "      <th>100</th>\n",
       "      <th>100m</th>\n",
       "      <th>100mg</th>\n",
       "      <th>10mg</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>138</th>\n",
       "      <th>...</th>\n",
       "      <th>yay</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourpenis</th>\n",
       "      <th>zach</th>\n",
       "      <th>zolpidem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 692 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0nline  100  100m  100mg  10mg  119  120  129  130  138  ...  yay  yeah  \\\n",
       "0       0    0     0      0     0    0    0    0    0    0  ...    0     0   \n",
       "1       0    0     0      0     0    0    0    0    0    0  ...    1     0   \n",
       "2       0    0     0      0     0    0    0    0    0    0  ...    0     0   \n",
       "3       0    0     0      0     0    0    0    0    0    0  ...    0     0   \n",
       "4       0    0     0      0     0    0    0    0    0    0  ...    0     0   \n",
       "\n",
       "   year  yesterday  york  you  your  yourpenis  zach  zolpidem  \n",
       "0     0          0     0    1     0          0     0         0  \n",
       "1     0          0     0    1     0          0     0         0  \n",
       "2     0          1     0    0     0          0     0         0  \n",
       "3     0          0     0    1     0          0     0         0  \n",
       "4     0          0     0    0     0          0     0         0  \n",
       "\n",
       "[5 rows x 692 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据集\n",
    "X = words.values\n",
    "y = np.array(class_list)\n",
    "testing_set = [int(num) for num in random.sample(range(50), 10)]\n",
    "training_set = list(set(range(50)) - set(testing_set))\n",
    "\n",
    "# 训练集\n",
    "Xtrain = []\n",
    "ytrain = []\n",
    "for doc_index in training_set:\n",
    "    Xtrain.append(X[doc_index])\n",
    "    ytrain.append(y[doc_index])\n",
    "\n",
    "# 测试集\n",
    "Xtest = []\n",
    "ytest = []\n",
    "for doc_index in testing_set:\n",
    "    Xtest.append(X[doc_index])\n",
    "    ytest.append(y[doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "model = NB(lambda_=0.2)\n",
    "model.fit(np.array(Xtrain), np.array(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确率：0.9\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "score = model.score(Xtest, ytest)\n",
    "print('正确率：{}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn 实现\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确率：0.9\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB().fit(Xtrain, ytrain)\n",
    "score = bnb.score(Xtest, ytest)\n",
    "print('正确率：{}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高斯朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P\\left(x_{i}|y_{k}\\right)=\\frac{1}{\\sqrt{2 \\pi \\sigma_{y_{k}, i}^{2}}} e^{-\\frac{(x_{i}-\\mu_{y_k, i}^2)^2}{2 \\sigma_{y_k, i}^{2}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNB:\n",
    "    def __init__(self):\n",
    "        self.parameters = {}\n",
    "        self.classes = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = list(np.unique(y))\n",
    "\n",
    "        for c in self.classes:\n",
    "            # 计算每个类别的平均值，方差，先验概率\n",
    "            X_Index_c = X[np.where(y == c)]\n",
    "            X_index_c_mean = np.mean(X_Index_c, axis=0, keepdims=True)\n",
    "            X_index_c_var = np.var(X_Index_c, axis=0, keepdims=True)\n",
    "            prior = X_Index_c.shape[0] / X.shape[0]\n",
    "            self.parameters[\"class\" + str(c)] = {\"mean\": X_index_c_mean, \"var\": X_index_c_var, \"prior\": prior}\n",
    "        # print(self.parameters)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 取概率最大的类别返回预测值\n",
    "        output = []\n",
    "        for y in self.classes:\n",
    "            # 先验概率\n",
    "            prior = np.log(self.parameters[\"class\" + str(y)][\"prior\"])\n",
    "\n",
    "            # 后验概率：一维高斯分布的概率密度函数\n",
    "            mean = self.parameters[\"class\" + str(y)][\"mean\"]\n",
    "            var = self.parameters[\"class\" + str(y)][\"var\"]\n",
    "\n",
    "            eps = 1e-4\n",
    "            numerator = np.exp(-(X - mean) ** 2 / (2 * var + eps))\n",
    "            denominator = np.sqrt(2 * np.pi * var + eps)\n",
    "\n",
    "            # 取对数防止数值溢出\n",
    "            posterior = np.sum(np.log(numerator / denominator), axis=1, keepdims=True).T\n",
    "            prediction = prior + posterior\n",
    "            output.append(prediction)\n",
    "\n",
    "        output = np.reshape(output, (len(self.classes), X.shape[0]))\n",
    "        prediction = np.argmax(output, axis=0)\n",
    "        return prediction\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        pred = self.predict(X_test)\n",
    "        right = (y_test - pred == 0.0).sum()\n",
    "\n",
    "        return right / float(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例：鸢尾花分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()  # 鸢尾花数据集\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['label'] = iris.target\n",
    "df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "data = np.array(df.iloc[:, :])\n",
    "# 构建数据集\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "model = GNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的类别是：[0]\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "ck = model.predict(np.array([4.4, 3.2, 1.3, 0.2]).reshape(1, -1))\n",
    "print(\"预测的类别是：{}\".format(ck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确率：0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "score = model.score(X_test, y_test)\n",
    "print('正确率：{}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn实现\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的类别是：[0.]\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "ck = gnb.predict([[4.4, 3.2, 1.3, 0.2]])\n",
    "print(\"预测的类别是：{}\".format(ck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确率：0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "score = gnb.score(X_test, y_test)\n",
    "print('正确率：{}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
